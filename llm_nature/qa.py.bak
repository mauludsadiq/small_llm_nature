from __future__ import annotations
from dataclasses import dataclass
from typing import List, Tuple
from .word_ngram import tokenize, WordNGram
from .dataset import QAItem

def jaccard(a: set[str], b: set[str]) -> float:
    if not a and not b:
        return 0.0
    return len(a & b) / len(a | b)

class QAReranker:
    """
    Minimal QA system:
      score_i = log p_theta("q: Q* a: A_i") + lam * sim(Q*, Q_i)
    where sim is Jaccard over token sets.
    """
    def __init__(self, k: int = 3, alpha: float = 0.5, lam: float = 0.0):
        self.lm = WordNGram(k=k, alpha=alpha)
        self.items: List[QAItem] = []
        self.lam = lam

    def fit(self, items: List[QAItem]) -> None:
        self.items = list(items)
        corpus_text = "\n".join([f"Q: {it.q}\nA: {it.a}\n" for it in self.items])
        self.lm.fit_text(corpus_text)

    def score(self, q_star: str, item: QAItem) -> Tuple[float, float, float]:
        lp = self.lm.log_prob_prompt_answer(q_star, item.a)
        sim = jaccard(set(tokenize(q_star)), set(tokenize(item.q)))
        total = lp + self.lam * sim
        return total, lp, sim

    def ranked(self, q_star: str) -> List[Tuple[QAItem, float, float, float]]:
        rows = []
        for it in self.items:
            total, lp, sim = self.score(q_star, it)
            rows.append((it, total, lp, sim))
        rows.sort(key=lambda r: r[1], reverse=True)
        return rows

    def answer(self, q_star: str) -> QAItem:
        return self.ranked(q_star)[0][0]
